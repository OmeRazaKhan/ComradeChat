"""
Module for parsing JSON file generated by the web scraper.
"""
import json
import pandas as pd

from python.database.metadata import Resource, MetaData


class Parser:
    def __init__(self):
        pass

    def _get_start_end_time(self, temporal_coverage: str):
        """
        Extracts the start and end dates from a string.
        """
        arr = temporal_coverage.split(" ")
        start = arr[0]
        start_dt = pd.to_datetime(start)
        end = arr[2]
        end_dt = pd.to_datetime(end)
        return start_dt, end_dt

    def _parse_resources(self, all_resources: dict):
        """
        Returns a list of all resources relevant to a dataset.
        """
        parsed_resources = []

        for resource in all_resources:
            title = None
            languages = None
            file_type = None
            miscellaneous = None
            url = None

            if "title" in resource:
                title = resource["title"]
            if "languages" in resource:
                languages = resource["languages"]
            if "file_type" in resource and not resource["file_type"] is None:
                file_type = resource["file_type"].lower()
            if "miscellaneous" in resource:
                miscellaneous = resource["miscellaneous"]
            if "resource_url" in resource:
                url = resource["resource_url"]
            parsed_resources.append(
                Resource(
                    title=title,
                    languages=languages,
                    file_type=file_type,
                    url=url,
                    miscellaneous=miscellaneous,
                )
            )
        return parsed_resources

    def parse(self, metadata_file_path: str) -> dict:
        """
        Parses a JSON file containing all metadata scraped from the open source portal.

        Params:
            metadata_file_path (str): The path to the file JSON containing all scraped metadata.

        Returns:
            (dict(id: MetaData)): The id of each metadata entry mapped to the MetaData itself.

        """
        with open(metadata_file_path, "r", encoding="utf-8") as f:
            datasets = json.load(f)

        all_metadata = {}

        # Load the metadata for each key.
        for id in datasets:
            current_dataset = datasets[id]
            dataset_id = int(id)

            keywords = None
            subjects = None
            audience = None
            start = None
            end = None
            resources = None

            try:
                url = current_dataset["dataset_url"]
                description = current_dataset["dataset_description"]

            except KeyError:
                print(
                    'Warning: Could not load id={} into database - missing "url" or "description" key'.format(
                        id, metadata_file_path
                    )
                )
                continue

            if "keywords" in current_dataset:
                keywords = current_dataset["keywords"]
            if "subjects" in current_dataset:
                subjects = current_dataset["subjects"]
            if "audience" in current_dataset:
                audience = current_dataset["audience"]
            if "temporal_coverage" in current_dataset:
                temporal_coverage = current_dataset["temporal_coverage"]
                start, end = self._get_start_end_time(temporal_coverage)
            if "resources" in current_dataset:
                resource_entry = current_dataset["resources"]
                resources = self._parse_resources(resource_entry)
            metadata = MetaData(
                dataset_id,
                description,
                url,
                keywords=keywords,
                subjects=subjects,
                audience=audience,
                start_date=start,
                end_date=end,
                resources=resources,
            )
            all_metadata[dataset_id] = metadata
        return all_metadata
